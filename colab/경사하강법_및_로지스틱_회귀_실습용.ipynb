{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/qwfCanZOyVq9aqvyay68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongrolee/Python/blob/main/colab/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95_%EB%B0%8F_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80_%EC%8B%A4%EC%8A%B5%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyh-cnd1WSVN"
      },
      "source": [
        "## SetUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Peu4chdMWSVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c7b5f66c-4494-42b6-d7f5-747f8ddcfd46"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6dd74869c25f>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 구글 드라이브 연결\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 일관된 출력을 위해 유사난수 초기화\n",
        "np.random.seed(42)\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "# sn.set()\n",
        "\n",
        "# 폰트출력\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
        "\n",
        "# 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNE96Hx6WSVN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDypHFcKWSVJ"
      },
      "source": [
        "# **모델 훈련**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8swLQLeWSVL"
      },
      "source": [
        "머신러닝 알고리즘이 어떻게 작동하는지 알고 있으면, 데이터 분석 목적에 맞는 적절한 모델 그리고 하이퍼파라미터를 빠르게 찾을 수 있음.\n",
        "\n",
        "가장 간단한 모델인 선형 회귀(Linear Regression)에 대해 다음과 같이 두 가지 방법을 통해 알아본다.\n",
        "\n",
        "> - 직접 계산할 수 있는 공식을 사용하여 Train Set에 가장 잘 맞는 파라미터를 구하는 방법\n",
        "- 경사하강법(Gradient Descent)를 이용하여 반복적인 최적화 방식을 사용해 파라미터를 조금씩 수정하면서 비용함수(cost function)를 Train Set에 대해 최소화시키는 파라미터를 구하는 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D4jiGwaAvsF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epzmBgPX6MoE"
      },
      "source": [
        "## **1.경사 하강법**\n",
        "\n",
        "경사 하강법에서 중요한 하이퍼파라미터는 **학습률**(learning rate, $\\eta$)이다. 학습률이 너무 작으면 수렴하는데까지 시간이 오래걸리고, 학습률이 너무 크면 발산하게 된다. 보통 로그 스케일로 0.001($10^{-3}$), 0.001($10^{-2}$)와 같이 지정한다.\n",
        "\n",
        "경사 하강법을 사용할 때는 반드시 모든 특성(feature)들이 같은 스케일을 가지도록 해야한다(Standard 또는 MinMax 등). 그렇지 않으면 학습시간이 오래걸리게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x4OwaSIR50l"
      },
      "source": [
        "#### 1)경사하강법을 이용한 물고기 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3z-zKXoRmWB"
      },
      "outputs": [],
      "source": [
        "# 데이터 읽어오기(fish_SGD.csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAiJVY9nR1fF"
      },
      "outputs": [],
      "source": [
        "# input과 target 준비\n",
        "# input  : 'Weight','Length','Diagonal','Height','Width'\n",
        "# target : 'Species'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW6LMW_URpto"
      },
      "outputs": [],
      "source": [
        "# Train Set 및 Test Set 분리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RTAwK_DRutj"
      },
      "outputs": [],
      "source": [
        "# 특성에 대한 표준화 적용(StandardScaler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KofoXhbwR9yu"
      },
      "outputs": [],
      "source": [
        "# 경사하강법을 이용한 학습 수행 (SGDClassifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Set과 Test Set을 통한 성능 측정\n"
      ],
      "metadata": {
        "id": "nzC4QA7YWBPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duwA4N3eSUk5"
      },
      "outputs": [],
      "source": [
        "# iteration 수행 (partial_fit)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Set과 Test Set을 통한 성능 재측정\n"
      ],
      "metadata": {
        "id": "VLMcW0kJWfLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEtfnUQhzKO2"
      },
      "source": [
        "##### 에포크와 과대/과소적합\n",
        "언제까지 iteration을 수행해야 적합할까?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt7BHZVZ-dWT"
      },
      "outputs": [],
      "source": [
        "# 반복문을 통해 성능 측정 결과 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-65Gz13tVOP7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V19SzZJ5ZjSI"
      },
      "outputs": [],
      "source": [
        "# 측정결과를 그래프로 출력 후 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdp2Ykst1K_I"
      },
      "outputs": [],
      "source": [
        "# 분석 결과에 따른 max_iter 파라미터 결정\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 모델 성능 평가\n"
      ],
      "metadata": {
        "id": "-UwlABHuYN4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL7-y1kgIP4S"
      },
      "outputs": [],
      "source": [
        "# loss function 바꿔보기 (hinge)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp16KTIP6MoE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PResbVuO6MoF"
      },
      "source": [
        "### 2) 경사 하강법이란?\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial w_j} MSE(\\mathbf{W}) = \\frac{2}{m} \\sum_{i=1}^{m}{\\left( \\mathbf{W}^{T} \\cdot \\mathbf{x}_{i} - y_{i}\\right)}x_{ij}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nklkVBFP6MoF"
      },
      "source": [
        "$$\n",
        "\\nabla_{\\mathbf{W}} \\text{MSE}(\\mathbf{W}) = \\begin{bmatrix} \\frac { \\partial  }{ \\partial w_{ i } } { MSE }(W) \\\\ \\vdots \\\\ \\frac { \\partial  }{ \\partial w_{ i } } { MSE }(W) \\end{bmatrix} = \\frac{2}{m} \\mathbf{X}^{T} \\cdot \\left( \\mathbf{X} \\cdot \\mathbf{W} - \\mathbf{y} \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYFy4CBE6MoF"
      },
      "source": [
        "#### 경사 하강법 Step\n",
        "\n",
        "$$\n",
        "\\mathrm{W} \\leftarrow \\mathrm{W} - \\eta \\nabla_{\\mathbf{W}} \\text{MSE}(\\mathbf{W}) \\Longleftrightarrow\n",
        " \\mathrm{W} \\leftarrow \\mathrm{W} - \\eta \\frac{\\partial L}{\\partial \\mathrm{W}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4QY92U06MoF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "eta = 0.1  # learning rate\n",
        "n_iterations = 1000\n",
        "m = 100\n",
        "weight = np.random.randn(2, 1)  # random init\n",
        "\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "X_b = np.c_[np.ones((100, 1)), X]  # x0 = 1 추가\n",
        "\n",
        "for step in range(n_iterations):\n",
        "    gradients = 2/m * X_b.T.dot(X_b.dot(weight) - y)\n",
        "    weight = weight - eta * gradients\n",
        "\n",
        "    if (step+1) % 200 == 0:\n",
        "        print('Step :{:04d}, weight = \\n {}'.format(step+1, weight))\n",
        "\n",
        "print('최종 결과값 : \\n{}'.format(weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsXQ3-3V6MoF"
      },
      "outputs": [],
      "source": [
        "weight_path_bgd = []\n",
        "\n",
        "def plot_gradient_descent(weight, eta, weight_path=None):\n",
        "    m = len(X_b)\n",
        "    plt.plot(X, y, \"b.\")\n",
        "    n_iterations = 1000\n",
        "    for iteration in range(n_iterations):\n",
        "        if iteration < 10:\n",
        "            y_predict = X_new_b.dot(weight)\n",
        "            style = \"b-\" if iteration > 0 else \"r--\"\n",
        "            plt.plot(X_new, y_predict, style)\n",
        "        gradients = 2/m * X_b.T.dot(X_b.dot(weight) - y)\n",
        "        weight = weight - eta * gradients\n",
        "        if weight_path is not None:\n",
        "            weight_path.append(weight)\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "    plt.axis([0, 2, 0, 15])\n",
        "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjAeaNrT6MoF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "weight = np.random.randn(2,1)  # random initialization\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(131); plot_gradient_descent(weight, eta=0.02)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.subplot(132); plot_gradient_descent(weight, eta=0.1, weight_path=weight_path_bgd)\n",
        "plt.subplot(133); plot_gradient_descent(weight, eta=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w6Ifvmy6MoF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZBYTmmn6MoI"
      },
      "source": [
        "### 3) 확률적 경사 하강법\n",
        "\n",
        "경사 하강법의 가장 큰 문제는 매 스텝(step)에서 전체 Train Set을 사용해 Gradient Descent를 계산한다는 것이다. 따라서, Train Set가 커지면 학습이 매우 느려지게 된다.\n",
        "\n",
        "이를 해결하기 위해, **확률적 경사 하강법**(Stochastic Gradient Descent)은 매 스텝에서 랜덤하게 하나의 데이터(샘플)을 선택해 Gradient Descent(GD)를 계산한다. 따라서, 전체 데이터를 이용해 GD를 계산하는 것보다 속도는 빠르지만 훨씬 불안정하다. 비용 함수(Loss Function)가 최소값에 수렴할 때까지 부드럽게 감소하지 않고, 위아래로 요동치면서 평균적으로 감소한다.\n",
        "\n",
        "이처럼 비용 함수가 불규칙하게 요동치면서 감소할 경우 지역 최소값(local minimum)을 건너뛸 수 있는 가능성이 있기 때문에, SGD가 전역 최소값(global minimum)을 찾을 가능성이 높다. 하지만 이러한 무작위성은 지역 최소값을 탈출할 수 있지만, 전역 최소값에는 다다르지 못하는 경우가 있다. 이를 해결하기 위해 학습률(learning rate)을 점진적으로 감소 시키는 **learning rate decay** 기법을 사용한다.\n",
        "\n",
        "learning rate decay(또는 learning rate schedule)는 학습을 시작할 때는 학습률을 크게하고, 점진적으로 학습률을 줄여 전역 최소값에 도달하게 하는 방법이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhWKI9rY6MoJ"
      },
      "outputs": [],
      "source": [
        "weight_path_sgd = []\n",
        "m = len(X_b)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJAGL4CL6MoJ"
      },
      "outputs": [],
      "source": [
        "n_epochs = 50\n",
        "t0, t1 = 5, 50\n",
        "\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "weight = np.random.randn(2, 1)  # random init\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(m):\n",
        "        if epoch == 0 and i < 20:\n",
        "            y_predict = X_new_b.dot(weight)\n",
        "            style = 'b-' if i > 0 else 'r--'\n",
        "            plt.plot(X_new, y_predict, style)\n",
        "\n",
        "        random_index = np.random.randint(m)\n",
        "        xi = X_b[random_index:random_index+1]\n",
        "        yi = y[random_index:random_index+1]\n",
        "        gradients = 2 * xi.T.dot(xi.dot(weight) - yi)\n",
        "        eta - learning_schedule(epoch * m + i)\n",
        "        weight = weight - eta * gradients\n",
        "        weight_path_sgd.append(weight)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print('Epoch :{:03d}, weight = \\n {}'.format(epoch+1, weight))\n",
        "\n",
        "\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([0, 2, 0, 15])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goa1R2Bg6MoJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN47AhXG6MoJ"
      },
      "source": [
        "Scikit-Learn에서는 SGD방법을 이용한 Regression인 `SGDRegressor` 클래스가 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnGJfGE-6MoJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "sgd_reg = SGDRegressor(max_iter=50, penalty=None, eta0=0.1, random_state=42)\n",
        "sgd_reg.fit(X, y.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiN0h4gg6MoK"
      },
      "outputs": [],
      "source": [
        "sgd_reg.intercept_, sgd_reg.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijo3BjwJ6MoK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB1lFgrP6MoK"
      },
      "source": [
        "### 4) 미니배치 경사 하강법\n",
        "\n",
        "**미니배치 경사 하강법**(Mini-batch Gradient Descent)은 각 스텝에서 전체 Train Set을  미니배치(mini-batch), 즉 작은 데이터셋을 추출한 뒤 Gradient를 계산하는 방법이다. 미니배치 경사하강법의 장점은 행렬 연산에 최적화된 하드웨어, GPU에서 빠르게 수행되는 것이다.\n",
        "\n",
        "미니배치 경사 하강법은 SGD에 비해 덜 불규칙하게 감소하지만, local minimum에 빠질 확률은 높은 경우가 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C19U5hh6MoK"
      },
      "outputs": [],
      "source": [
        "weight_path_mgd = []\n",
        "\n",
        "n_iterations = 100\n",
        "minibatch_size = 20\n",
        "\n",
        "np.random.seed(42)\n",
        "weight = np.random.randn(2,1)  # random init\n",
        "\n",
        "t0, t1 = 200, 1000\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "t = 0\n",
        "for epoch in range(n_iterations):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_b_shuffled = X_b[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    for i in range(0, m, minibatch_size):\n",
        "        t += 1\n",
        "        xi = X_b_shuffled[i:i+minibatch_size]\n",
        "        yi = y_shuffled[i:i+minibatch_size]\n",
        "        gradients = 2/minibatch_size * xi.T.dot(xi.dot(weight) - yi)\n",
        "        eta = learning_schedule(t)\n",
        "        weight = weight - eta * gradients\n",
        "        weight_path_mgd.append(weight)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print('Epoch :{:03d}, weight = \\n {}'.format(epoch+1, weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjASSgff6MoK"
      },
      "outputs": [],
      "source": [
        "weight_path_bgd = np.array(weight_path_bgd)\n",
        "weight_path_sgd = np.array(weight_path_sgd)\n",
        "weight_path_mgd = np.array(weight_path_mgd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6TTrPJV6MoK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(weight_path_sgd[:, 0], weight_path_sgd[:, 1], \"r-s\", linewidth=1, label=\"SGD\")\n",
        "plt.plot(weight_path_mgd[:, 0], weight_path_mgd[:, 1], \"g-+\", linewidth=2, label=\"Mini batch\")\n",
        "plt.plot(weight_path_bgd[:, 0], weight_path_bgd[:, 1], \"b-o\", linewidth=3, label=\"Batch\")\n",
        "plt.legend(loc=\"upper left\", fontsize=16)\n",
        "plt.xlabel(r\"$\\theta_0$\", fontsize=20)\n",
        "plt.ylabel(r\"$\\theta_1$   \", fontsize=20, rotation=0)\n",
        "plt.axis([2.5, 4.5, 2.3, 3.9])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUkpn05_6MoL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLMyK1cO6MoV"
      },
      "source": [
        "## **2.로지스틱 회귀 (Logistic Regression)**\n",
        "\n",
        "로지스틱 회귀는 이진 분류 알고리즘 중 하나인 모델이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J2jb1TA6MoV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1)로지스틱 회귀로 물고기 분류해 보기"
      ],
      "metadata": {
        "id": "9DT_wpdVEPol"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKe_Y7kGAgxd"
      },
      "source": [
        "#### 데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RfSx-cI6vOJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JjMXc9wVE7C"
      },
      "outputs": [],
      "source": [
        "# 특성 input 데이터 가져오기 ('Weight','Length','Diagonal','Height','Width')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB2oHhojTfWE"
      },
      "outputs": [],
      "source": [
        "# target 데이터 가져오기('Species')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkllezAJW63K"
      },
      "outputs": [],
      "source": [
        "# Train Set 및 Test Set 데이터 분리하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ujq0BjXpfp"
      },
      "outputs": [],
      "source": [
        "# 특성 표준화하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <실습> 시그모이드 함수를 그래프로 출력해 보세요.\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}\n",
        "$$"
      ],
      "metadata": {
        "id": "JJn4ZWcbdy9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rdDSaZ5uji2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J6LGKpUJbFE"
      },
      "source": [
        "#### 로지스틱 회귀로 이진 분류 수행하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khxh-3t5-2Tk"
      },
      "outputs": [],
      "source": [
        "# 'Bream' 와 'Smelt' 데이터 가져와 Train Set 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEzP0aeXANra"
      },
      "outputs": [],
      "source": [
        "# 로지스틱 회귀로 훈련시키기 (LogisticRegression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtEWtsB7EIgm"
      },
      "outputs": [],
      "source": [
        "# 결과 예측해 보기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H_qieV-_CTt"
      },
      "outputs": [],
      "source": [
        "# 확률 측정 (predict_proba())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm60bpr7EQKU"
      },
      "outputs": [],
      "source": [
        "# 어떤 것이 양성 클래스(1)인지 확인, Smelt가 양성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mvoYhUVQmFY"
      },
      "outputs": [],
      "source": [
        "# coef_ 및 intercept_ 값 확인\n",
        "# t = -0.404*(Weight) - 0.576*(Length) - 0.663*(Diagonal) - 1.013*(Height) -0.732*(Width) -2.161\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxrRy9m8A5Hy"
      },
      "outputs": [],
      "source": [
        "# t 값 계산 (decision_function())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeuhSRuiA9yZ"
      },
      "outputs": [],
      "source": [
        "# t값을 시그모이드 함수에 적용하여 확률 계산, predict_proba()의 양성클래스 결과와 비교\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ee-s4l7EuVo"
      },
      "source": [
        "#### 로지스틱 회귀로 다중 분류 수행하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QugsbD2X8bf"
      },
      "outputs": [],
      "source": [
        "# LogisticRegression 적용 (C=규제(작을수록 큰 규제), max_iter=반복횟수))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 평가\n"
      ],
      "metadata": {
        "id": "VH_JZfcxgvm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0taO0XnF9dha"
      },
      "outputs": [],
      "source": [
        "# 예측\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqZosYezZOi3"
      },
      "outputs": [],
      "source": [
        "# 확률 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXASv4WU87UF"
      },
      "outputs": [],
      "source": [
        "# 클래스 정보 출력하여 위 확률 정보와 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1swPv6ZOZTjg"
      },
      "outputs": [],
      "source": [
        "# 방정식 계수 도출(coef_.shape, intercept_.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9iRz1iAd7Oe"
      },
      "outputs": [],
      "source": [
        "# z값 또는 t값 계산 (decision_function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49CcsDHZeJma"
      },
      "outputs": [],
      "source": [
        "# 소프트맥스 함수 적용\n",
        "# 여러개의 선형 방정식 출력값을 0~1로 압축하고 전체 합이 1이 되도록 만듦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MdVWO-ndDoVv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTHSVa0M6MoV"
      },
      "source": [
        "### 2) 확률 추정\n",
        "\n",
        "로지스틱 회귀는 선형 회귀(linear regression)과 같이 입력 특성(feature)의 가중치 합을 계산한 뒤 로지스틱 함수(sigmoid)를 적용해 출력값을 계산한다.\n",
        "\n",
        "$$\n",
        "\\hat{p} = h_{w}(\\mathbf{x}) = \\sigma \\left( \\mathbf{W}^{T} \\cdot \\mathbf{x} \\right)\n",
        "$$\n",
        "\n",
        "위의 식에서 $\\sigma(\\cdot)$이 바로 로지스틱(또는 로짓) 함수이며 0과 1사이의 값을 출력하는 **시그모이드 함수**(sigmoid function)이다.\n",
        "\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZocoTwY6MoV"
      },
      "source": [
        "로지스틱 회귀의 모델은 아래와 같이 할 수 있다. 하지만, 상황에 따라 임계값(threshold)를 조절해줄 수 있다.\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\begin{cases} 0 \\quad \\hat{p} < 0.5 \\\\ 1 \\quad \\hat{p} \\ge 0.5 \\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QphttA07DJh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ullw773F6MoV"
      },
      "outputs": [],
      "source": [
        "t = np.linspace(-10, 10, 100)\n",
        "sig = 1 / (1 + np.exp(-t))\n",
        "\n",
        "plt.figure(figsize=(9, 3))\n",
        "plt.plot([-10, 10], [0, 0], \"k-\")\n",
        "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
        "plt.plot([-10, 10], [1, 1], \"k:\")\n",
        "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
        "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.legend(loc=\"upper left\", fontsize=20)\n",
        "plt.axis([-10, 10, -0.1, 1.1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkN4Oq7m6MoV"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv7kqce_6MoV"
      },
      "source": [
        "### 3) 훈련과 비용 함수\n",
        "\n",
        "Logistic Regression의 학습 데이터 하나에 대한 **비용 함수**는 다음과 같다.\n",
        "\n",
        "$$\n",
        "c(\\mathbf{W}) = \\begin{cases} -\\log{\\left( \\hat{p} \\right)} \\quad \\text{if, }y=1 \\\\ -\\log{\\left(1-\\hat{p}\\right)} \\quad \\text{if, }y = 0 \\end{cases}\n",
        "$$\n",
        "*   모델이 양성 샘플을 0에 가까운 확률로 추정하면 비용이 증가\n",
        "*   모델이 음성 샘플을 1에 가까운 확률로 추정해도 비용이 증가\n",
        "*   t가 0에 가까우면 -$log{(t)}$는 매우 커짐\n",
        "*   t가 1에 가까우면 -$log{(t)}$는 0에 가까워짐\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxIaEnYB6MoW"
      },
      "source": [
        "전체 Train Set에 대한 비용 함수는 모든 데이터에 대한 비용의 평균이며, 이것을 **로그 손실**(log loss)이라고 한다.\n",
        "\n",
        "$$\n",
        "J(\\mathbf{W}) = - \\frac{1}{m} \\sum_{i=1}^{m}{\\left[ y_{i} \\log{\\left( \\hat{p}_i \\right)} + \\left( 1 - y_i \\right) \\log{\\left( 1 - \\hat{p}_i \\right)} \\right]}\n",
        "$$\n",
        "*   이 로그손실은 볼록 함수이므로 경사 하강법이 전역 최소값을 찾는 것을 보장(학습률이 너무 크지 않아야 함)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpCEd3B66MoW"
      },
      "source": [
        "로그 손실을 $\\mathbf{W}$로 미분하면 다음과 같다.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m}{\\left( \\sigma \\left( \\mathbf{W}^{T} \\cdot \\mathbf{x}_i \\right) - \\mathbf{y}_i \\right)} x_{ij}\n",
        "$$\n",
        "*   각 샘플에 대한 예측오차를 계산하고 j번째 특성값을 곱해서 모든 특성 훈련 샘플에 대해 평균을 냅니다.\n",
        "*   모든 편도함수를 포함한 그레디언트 벡터를 만들면 배치 경사하강법 알고리즘 사용도 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IZudwPw6MoW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxvmfvj16MoW"
      },
      "source": [
        "### 4) 결정 경계\n",
        "\n",
        "로지스틱 회귀를 iris(붓꽃) 데이터 셋을 이용해 알아보자.\n",
        "\n",
        "- sepal length: 꽃받침 길이\n",
        "- sepal width: 꽃받침 너비\n",
        "- petal length: 꽃잎 길이\n",
        "- petal width: 꽃잎 너비\n",
        "\n",
        "![](./images/iris.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aohsi5oD6MoW"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "list(iris.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris"
      ],
      "metadata": {
        "id": "P9clneADrpfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFhjnzVE6MoW"
      },
      "outputs": [],
      "source": [
        "print(iris.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0bwCD3N6MoW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBObeCYB6MoX"
      },
      "outputs": [],
      "source": [
        "iris_df = pd.DataFrame(iris['data'], columns=iris.feature_names)\n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.info()"
      ],
      "metadata": {
        "id": "AmBfEdjfsxnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z1NVne-6MoX"
      },
      "outputs": [],
      "source": [
        "iris_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BISAtlwL6MoX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6lChGT16MoX"
      },
      "source": [
        "#### Petal width를 이용한 Verginca 종 분류기 구현\n",
        "\n",
        "먼저 꽃잎의 너비를 이용해 iris 중에서 Verginca 종을 분류하는 분류기를 만들어 보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_dpd6HB6MoX"
      },
      "outputs": [],
      "source": [
        "X = iris['data'][:, 3:]  # 꽃잎 너비\n",
        "y = (iris['target'] == 2).astype(np.int)  # Verginica면 1 아니면 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "EOkgfvoDrI2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qncTVmEL6MoX"
      },
      "outputs": [],
      "source": [
        "# LogisticRegression을 이용한 학습\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPlalF406MoY"
      },
      "outputs": [],
      "source": [
        "# 확률 계산 (predict_proba)\n",
        "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba"
      ],
      "metadata": {
        "id": "bT5yxJtQwyXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(X[y==0], y[y==0], \"bs\")\n",
        "plt.plot(X[y==1], y[y==1], \"r^\")\n",
        "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
        "plt.plot(X_new, y_proba[:, 1], \"r-\", linewidth=2, label=\"Iris-Virginica\")\n",
        "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris-Virginica\")\n",
        "plt.text(decision_boundary+0.02, 0.15, \"Decision Boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
        "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
        "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='r', ec='r')\n",
        "plt.xlabel(\"Width of Petal (cm)\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"center left\", fontsize=14)\n",
        "plt.axis([0, 3, -0.02, 1.02])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0t9UiMZypw7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN9mLuCk6MoY"
      },
      "outputs": [],
      "source": [
        "log_reg.predict([[1.7], [1.5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-471BSH6MoY"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JJ6q0f76MoY"
      },
      "source": [
        "#### Petal width, Petal length를 이용한 Verginca 분류기 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcRXO03d6MoY"
      },
      "outputs": [],
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
        "y = (iris[\"target\"] == 2).astype(np.int)\n",
        "\n",
        "log_reg = LogisticRegression(C=10**10, random_state=42)\n",
        "log_reg.fit(X, y)\n",
        "\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(2.9, 7, 500).reshape(-1, 1),\n",
        "        np.linspace(0.8, 2.7, 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
        "\n",
        "zz = y_proba[:, 1].reshape(x0.shape)\n",
        "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
        "\n",
        "\n",
        "left_right = np.array([2.9, 7])\n",
        "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
        "\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
        "plt.text(3.5, 1.5, \"non-Iris-Virginica\", fontsize=14, color=\"b\", ha=\"center\")\n",
        "plt.text(6.5, 2.3, \"Iris-Virginica\", fontsize=14, color=\"g\", ha=\"center\")\n",
        "plt.xlabel(\"Length of Petal\", fontsize=14)\n",
        "plt.ylabel(\"Width of Petal\", fontsize=14)\n",
        "plt.axis([2.9, 7, 0.8, 2.7])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUJdBKUc6MoZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy6cULkN6MoZ"
      },
      "source": [
        "### 5) 소프트맥스 회귀 (Softmax Regression)\n",
        "\n",
        "로지스틱 회귀 모델은 여러개의 이진 분류기를 만들지 않고, 다중 클래스(multinomial class) 분류에 적용할 수 있다. 이것을 **소프트맥스 회귀**(Softmax Regression) 또는 **다항 로지스틱 회귀**(Multinomial Logistic Regression)이라고 한다.\n",
        "\n",
        "소프트맥스 회귀의 개념은 데이터 $x$에 대해 소프트맥스 회귀 모델이 각 클래스 $k$에 대한 점수(score) $S_k \\left( x \\right)$를 계산하고, 그 점수값에 **소프트맥스 함수**(softmax function)를 적용하여 각 클래스의 확률을 예측하는 모델이다.\n",
        "\n",
        "$$\n",
        "S_k \\left( \\mathbf{x} \\right) = \\left( \\mathbf{W}_{k} \\right)^{T} \\cdot \\mathbf{x}\n",
        "$$\n",
        "\n",
        "- $\\mathbf{W}_{k}$ : 각 클래스별 가중치 파라미터 벡터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AtvujHk6MoZ"
      },
      "source": [
        "위의 식을 이용해 소프트 맥스 함수를 적용한 식은 다음과 같다.\n",
        "\n",
        "$$\n",
        "\\hat{p}_k = \\sigma \\left( s(\\mathbf{x}) \\right)_k = \\frac{ \\text{exp} \\left( S_k(\\mathbf{x}) \\right)}{\\sum_{j=1}^{K}{\\text{exp} \\left( S_j (\\mathbf{x}) \\right)}}\n",
        "$$\n",
        "\n",
        "- $K$ : 클래스의 수\n",
        "- $s(\\mathbf{x})$ : 데이터 샘플 $\\mathbf{x}$에 대한 각 클래스의 점수를 담고 있는 벡터\n",
        "- $\\sigma \\left( S(\\mathbf{x}) \\right)_k$ : 샘플 $\\mathbf{x}$에 대한 클래스 $k$에 속할 추정 확률 벡터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMF-AKCS6MoZ"
      },
      "source": [
        "위의 식에서 추정된 확률 벡터 중 확률이 가장 높은 클래스로 분류가 된다. 이를 식으로 나타내면 다음과 같다.\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\underset{k}{\\text{arg}} \\max{\\sigma \\left( S(\\mathbf{x}) \\right)_k} = \\underset{k}{\\text{arg}} \\max{S_k(\\mathbf{x})} = \\underset{k}{\\text{arg}} \\max{\\left( \\mathbf{W_k}^{T} \\cdot \\mathbf{x}\\right) }\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKVf54j6MoZ"
      },
      "source": [
        "소프트맥스 회귀의 학습을 위한 손실함수(loss function)은 **크로스 엔트로피**(cross entropy)이며 다음과 같다.\n",
        "\n",
        "$$\n",
        "J(\\mathbf{W}) = - \\frac{1}{m} \\sum_{i=1}^{m}{\\sum_{k=1}^{K}{y_k^{(i)} \\log{\\left( \\hat{p}_k^{(i)} \\right)}}}\n",
        "$$\n",
        "\n",
        "- $i$번째 샘플에 대한 타겟 클래스가 $k$일 때, $y_k^{(i)}$가 1이고, 나머지는 0이 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6cUF5gr6MoZ"
      },
      "source": [
        "위의 손실함수에 대한 그래디언트 벡터는 다음과 같다.\n",
        "\n",
        "$$\n",
        "\\nabla_{w^{(k)}} J(\\mathbf{W}) = \\frac{1}{m} \\sum_{i=1}^{m}{\\left( \\hat{p}_k^{(i)} - y_k^{(i)} \\right)\\mathbf{x}^{(i)}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69RLX5nk6Moa"
      },
      "source": [
        "#### Scikit-Learn `LogisticRegression`을 이용해 Softmax Regression 사용하기\n",
        "\n",
        "Scikit-Learn에서 [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)은 셋 이상의 다중 클래스 분류에서는 기본적으로 일대다(OvA)를 디폴트 값으로 사용하지만, `multi_class`인자를 `multinomial`로 설정하면 Softmax Regression을 사용할 수 있다. 또한 `solver` 인자에 `lbfgs`로 지정해야한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paC49-Tp6Moa"
      },
      "outputs": [],
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 너비\n",
        "y = iris[\"target\"]\n",
        "\n",
        "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n",
        "softmax_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBY0qtC06Moa"
      },
      "outputs": [],
      "source": [
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
        "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "\n",
        "\n",
        "y_proba = softmax_reg.predict_proba(X_new)\n",
        "y_predict = softmax_reg.predict(X_new)\n",
        "\n",
        "zz1 = y_proba[:, 1].reshape(x0.shape)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris-Virginica\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris-Versicolor\")\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris-Setosa\")\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "plt.xlabel(\"Length of Petal\", fontsize=14)\n",
        "plt.ylabel(\"Width of Petal\", fontsize=14)\n",
        "plt.legend(loc=\"center left\", fontsize=14)\n",
        "plt.axis([0, 7, 0, 3.5])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVaPkO3S6Moa"
      },
      "outputs": [],
      "source": [
        "softmax_reg.predict([[5, 2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywWbftET6Mob"
      },
      "outputs": [],
      "source": [
        "softmax_reg.predict_proba([[5, 2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLztw8cN6Mob"
      },
      "source": [
        "### Logistic Regression vs Softmax Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVaFJvC06Mob"
      },
      "source": [
        "![](./images/logistic_regression_schematic.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdYghTUY6Mob"
      },
      "source": []
    }
  ]
}